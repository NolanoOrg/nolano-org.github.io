---
title: About
layout: page
description: About
bodyClass: page-about
---

Welcome to Nolano,

Our primary focus is on drastically reducing the cost of running large-scale generative AI models by (1) developing and deploying state-of-art model compression techniques and (2) enabling fast inference in such compressed models.  We aim to maximally reduce the size and inference cost of modern generative AI models, while maintaining their capabilities. Our models are designed to be easily deployable across a variety of platforms and applications, from mobile devices to cloud-based servers, providing a versatile solution for businesses and individuals alike. A wide range of  benefits provided by compressed foundation models include, but are not limited to:

1. Machine Learning Research: To optimize Large Language Models (LLMs) on personal hardware using techniques like better training, quantization, pruning, and knowledge distillation.

2. Easy-to-use API: To ensure rapid AI inference and ease model integration across various applications.

Additionally, we're offering Compression as a Service, reducing the size of your models for efficiency. Our open-source libraries aim to make AI more accessible and usable.



